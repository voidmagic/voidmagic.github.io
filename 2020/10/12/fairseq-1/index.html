<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no">
    
    <meta name="renderer" content="webkit"/>
    <meta name="force-rendering" content="webkit"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <script>if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode)) window.location.href="https://support.dmeng.net/upgrade-your-browser.html?referrer="+encodeURIComponent(window.location.href); </script>
    
    
        <link rel="preload" crossorigin="crossorigin" href="/fonts/roboto/Roboto-Regular.woff2" as="font">
        <link rel="preload" crossorigin="crossorigin" href="/fonts/roboto/Roboto-Bold.woff2" as="font">
    
    
    
        <link rel="shortcut icon" href="/icons/favicon.ico">
    

    
    
        
<link rel="stylesheet" href="/css/mdui.min.v1.0.0.css">

    
    
<link rel="stylesheet" href="/css/main.css">
<link rel="stylesheet" href="/css/iconfont.css">


    
    












          


    
    
    <title>
        
            Fairseq漫游指南（1）——命令行工具 | Qian Wang
        
    </title>
    
    
<meta name="generator" content="Hexo 5.2.0"></head>
<body class="mdui-drawer-body-left mdui-appbar-with-toolbar mdui-theme-primary-teal mdui-theme-accent-blue">
  
  <header class="mdui-appbar mdui-appbar-fixed">
  <div id="toolbar" class="mdui-toolbar mdui-color-theme">
    <button class="mdui-btn mdui-btn-icon" mdui-drawer="{target: '#sidebar', swipe: true}"><i class="iconfont icon-menu"></i></button>
    <a href="/" class="mdui-typo-headline">Qian Wang</a>
    <a href="/" class="header-subtitle mdui-typo-headline"></a>
    <div class="mdui-toolbar-spacer"></div>
  </div>
</header>

  <aside id="sidebar" class="mdui-drawer">
    
    
    <div id="sidebar-tab2" class="mdui-p-a-2">
        <div class="sidebar-overview">
            <div class="sidebar-avatar">
                
                    <img src="/icons/avatar.gif"/>
                
            </div>
            <div class="sidebar-author-name">Qian Wang</div>
            <div class="sidebar-description"></div>
        </div>
    </div>


    
    <div id="sidebar-tab1" class="mdui-p-a-2">
        <div class="mdui-list">
            
                
                <a href="/" class="mdui-list-item mdui-ripple">
                    <div class="mdui-list-item-icon">
                        <i class="iconfont icon-home"></i>
                    </div>
                    <div class="mdui-list-item-content">主页</div>
                </a>
            
                
                <a href="/tags/" class="mdui-list-item mdui-ripple">
                    <div class="mdui-list-item-icon">
                        <i class="iconfont icon-bookmark"></i>
                    </div>
                    <div class="mdui-list-item-content">标签</div>
                </a>
            
                
                <a href="/categories/" class="mdui-list-item mdui-ripple">
                    <div class="mdui-list-item-icon">
                        <i class="iconfont icon-folder"></i>
                    </div>
                    <div class="mdui-list-item-content">分类</div>
                </a>
            
                
                <a href="/about/" class="mdui-list-item mdui-ripple">
                    <div class="mdui-list-item-icon">
                        <i class="iconfont icon-user"></i>
                    </div>
                    <div class="mdui-list-item-content">关于</div>
                </a>
            
            <div class="mdui-list-item mdui-ripple">
                <div class="mdui-list-item-icon">
                    <i class="iconfont icon-moon"></i>
                </div>
                <div class="mdui-list-item-content">夜间模式</div>
                <label class="mdui-switch" id="darkmode">
                  <input type="checkbox" id="nightmode_switch"/>
                  <i class="mdui-switch-icon"></i>
                </label>
            </div>           
        </div>
        
        <div class="sidebar-links">
            
                
                <div class="mdui-chip">
                    <span class="mdui-chip-icon"><i class="iconfont icon-mail"></i></span>
                    <a href="mailto:qian.wang@nlpr.ia.ac.cn" class="mdui-chip-title">E-Mail</a>
                </div>
            
                
                <div class="mdui-chip">
                    <span class="mdui-chip-icon"><i class="iconfont icon-github"></i></span>
                    <a target="_blank" rel="noopener" href="https://github.com/voidmagic" class="mdui-chip-title">GitHub</a>
                </div>
            
        </div>
    </div>

</aside>
  
  <main id="main-contain" class="mdui-container mdui-m-t-5">
    <article id="article" class="mdui-card mdui-p-b-2 mdui-m-b-5">
  <header class="mdui-card-media">
    
    
      <div class="post-header"> 
  <a class="post-header-title" href="/2020/10/12/fairseq-1/">Fairseq漫游指南（1）——命令行工具</a>
  <div class="post-header-meta">
    <span>
      <span class="iconfont icon-calendar"></span>
      发布于:&nbsp;2020-10-12
    </span>
    <span>
      <span class="iconfont icon-calendar-check"></span>
      更新于:&nbsp;2020-10-12
    </span>
    <span>
      <span class="iconfont icon-folder"></span>
      分类于:&nbsp;
    </span>
    
  </div>
</div>   
    



    
    
    <!-- <div class="mdui-card-menu">
    
      <button class="mdui-btn mdui-btn-icon mdui-text-color-teal" mdui-menu="{target: '#share_menu', align: 'right'}"><i class="iconfont icon-share"></i></button>
      <ul class="mdui-menu" id="share_menu">
        <li class="mdui-menu-item">
          <a href="http://service.weibo.com/share/share.php?appkey=&title=Fairseq漫游指南（1）——命令行工具&url=http://example.com/2020/10/12/fairseq-1/&pic=http://example.com/null&searchPic=false&style=simple" target="_blank" class="mdui-ripple">分享到 Weibo</a>
        </li>
        <li class="mdui-menu-item">
          <a href="https://twitter.com/intent/tweet?text=Fairseq漫游指南（1）——命令行工具&url=http://example.com/2020/10/12/fairseq-1/&via=Qian Wang" target="_blank" class="mdui-ripple">分享到 Twitter</a>
        </li>
        <li class="mdui-menu-item">
          <a href="https://www.facebook.com/sharer/sharer.php?u=http://example.com/2020/10/12/fairseq-1/" target="_blank" class="mdui-ripple">分享到 Facebook</a>
        </li>
        <li class="mdui-menu-item">
          <a href="https://plus.google.com/share?url=http://example.com/2020/10/12/fairseq-1/" target="_blank" class="mdui-ripple">分享到 Google+</a>
        </li>
        <li class="mdui-menu-item">
          <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://example.com/2020/10/12/fairseq-1/&title=Fairseq漫游指南（1）——命令行工具" target="_blank" class="mdui-ripple">分享到 LinkedIn</a>
        </li>
        <li class="mdui-menu-item">
          <a href="http://connect.qq.com/widget/shareqq/index.html?site=Qian Wang&title=Fairseq漫游指南（1）——命令行工具&summary=&pics=http://example.com/null&url=http://example.com/2020/10/12/fairseq-1/" target="_blank" class="mdui-ripple">分享到 QQ</a>
        </li>
        <li class="mdui-menu-item">
          <a href="https://telegram.me/share/url?url=http://example.com/2020/10/12/fairseq-1/&text=Fairseq漫游指南（1）——命令行工具" target="_blank" class="mdui-ripple">分享到 Telegram</a>
        </li>
      </ul>
    
  </div> -->
  </header>
  
  
  
  <div class="mdui-card-content mdui-typo mdui-p-x-4">
    <p>2017年9月，Facebook AI Research开源了序列建模工具Fairseq。作为对Lua/Torch版本的改进，新款Fairseq基于Python和Pytorch，更加简单易用人性化。经过三年的迭代，fairseq目前已经拥有近两百位contributor，总代码量7万余行，功能和规模都已不同往日。</p>
<p>作为一个通用的序列建模工具，fairseq可以在多个自然语言处理任务上使用，如机器翻译、自动摘要、语音识别等文本生成任务，或者BERT、GPT等语言模型的训练；同时fairseq还实现了目前常用的多数模型，如RNN、CNN、Transformer、RoBERTa、XLM等。除了大量内置的任务和模型，fairseq还提供了极为简洁的接口，以便于使用者扩展已有模型、验证新的想法。</p>
<p>本文将以训练Transformer-based机器翻译模型为例，介绍fairseq的基本使用方法。</p>
<hr>
<h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>深度神经网络模型的训练需要GPU支持，因此硬件方面需要安装有NVIDIA GPU的服务器，这里以GTX1080（驱动版本430.64，CUDA版本10.1）的Ubuntu 16.04为例，其他GPU、驱动、操作系统可能有细微差异。为了保证环境的一致性，在环境搭建中将从pytorch的安装开始。</p>
<ol>
<li>安装pytorch</li>
</ol>
<p>使用conda安装pytorch的时候，可以同时指定CUDA版本，意思是安装使用指定CUDA预编译的pytorch：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">conda</span> create -n fairseq python=<span class="number">3</span>.<span class="number">7</span></span><br><span class="line"><span class="attribute">conda</span> install pytorch=<span class="number">1</span>.<span class="number">6</span> torchvision cudatoolkit=<span class="number">10</span>.<span class="number">1</span> -c pytorch -y </span><br></pre></td></tr></table></figure>

<ol start="2">
<li>安装fairseq</li>
</ol>
<p>由于直接使用pip安装的fairseq版本（0.9.0）还停留在2019年12月，为了使用更新的特性，我们选择GitHub上的最新版本（commit 77983ee）：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/pytorch/</span>fairseq.git</span><br><span class="line">cd fairseq &amp;&amp; git checkout <span class="number">522</span>c76b &amp;&amp; pip install --editable ./</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>安装apex（可选）</li>
</ol>
<p>Apex是NVIDIA为Pytorch开发的混合精度训练库，在多卡训练、半精度训练的过程中可以带来更快的训练效率。安装apex的时候需要注意，由于安装过程会编译CUDA代码，且需要与pytorch使用同一版本的CUDA编译，因此要先安装与pytorch一致的CUDA。下面的命令会下载10.1版本的CUDA，并将其安装在用户目录下（不需要管理员权限），之后用其编译安装apex：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https:<span class="regexp">//</span>developer.nvidia.com<span class="regexp">/compute/</span>cuda<span class="regexp">/10.1/</span>Prod<span class="regexp">/local_installers/</span>cuda_10.<span class="number">1.105</span>_418.<span class="number">39</span>_linux.run</span><br><span class="line">mkdir <span class="variable">$HOME</span><span class="regexp">/.cuda &amp;&amp; sh cuda_10.1.105_418.39_linux.run --silent --toolkit --toolkitpath=$HOME/</span>.cuda --defaultroot=<span class="variable">$HOME</span>/.cuda</span><br><span class="line">export CUDA_HOME=<span class="variable">$HOME</span>/.cuda</span><br><span class="line">git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/NVIDIA/</span>apex</span><br><span class="line">cd apex &amp;&amp; pip install -v --no-cache-dir --global-option=<span class="string">&quot;--cpp_ext&quot;</span> --global-option=<span class="string">&quot;--cuda_ext&quot;</span> ./</span><br></pre></td></tr></table></figure>


<ol start="4">
<li>验证安装</li>
</ol>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">python</span> <span class="selector-tag">-c</span> &quot;<span class="selector-tag">import</span> <span class="selector-tag">torch</span>;<span class="selector-tag">print</span>(<span class="selector-tag">torch</span><span class="selector-class">.__version__</span>, <span class="selector-tag">torch</span><span class="selector-class">.version</span><span class="selector-class">.cuda</span>)&quot;</span><br></pre></td></tr></table></figure>
<p>会显示pytorch版本（1.6.0）和对应cuda版本（10.1）；</p>
<figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -<span class="keyword">c</span> <span class="string">&quot;import fairseq;print(fairseq.__version__)&quot;</span></span><br></pre></td></tr></table></figure>
<p>会显示fairseq版本（0.9.0）；</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">python</span> <span class="selector-tag">-c</span> &quot;<span class="selector-tag">import</span> <span class="selector-tag">fairseq</span>;<span class="selector-tag">print</span>(<span class="selector-tag">fairseq</span><span class="selector-class">.utils</span><span class="selector-class">.multi_tensor_l2norm_available</span>)&quot;</span><br></pre></td></tr></table></figure>
<p>会显示apex是否成功安装（True）。</p>
<h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><p>在机器翻译中，需要双语平行数据来进行模型的训练，在这里使用fairseq中提供的数据：<br><code>bash fairseq/examples/translation/prepare-iwslt14.sh</code></p>
<p>这个脚本会下载IWSLT 14 英语和德语的平行数据，并进行分词、BPE等操作，处理的结果为：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">iwslt14.tokenized.<span class="keyword">de</span>-<span class="keyword">en</span></span><br><span class="line">├── code</span><br><span class="line">├── <span class="keyword">test</span>.<span class="keyword">de</span></span><br><span class="line">├── <span class="keyword">test</span>.<span class="keyword">en</span></span><br><span class="line">├── tmp</span><br><span class="line">├── train.<span class="keyword">de</span></span><br><span class="line">├── train.<span class="keyword">en</span></span><br><span class="line">├── valid.<span class="keyword">de</span></span><br><span class="line">└── valid.<span class="keyword">en</span></span><br></pre></td></tr></table></figure>


<h2 id="数据二进制化"><a href="#数据二进制化" class="headerlink" title="数据二进制化"></a>数据二进制化</h2><p>之后，使用fairseq的预处理命令fairseq-preprocess将文本数据转换为二进制的文件：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fairseq-preprocess --source-lang <span class="keyword">de</span> --target-lang <span class="keyword">en</span> \</span><br><span class="line">    --trainpref iwslt14.tokenized.<span class="keyword">de</span>-<span class="keyword">en</span>/train \</span><br><span class="line">    --validpref iwslt14.tokenized.<span class="keyword">de</span>-<span class="keyword">en</span>/valid \</span><br><span class="line">    --testpref iwslt14.tokenized.<span class="keyword">de</span>-<span class="keyword">en</span>/<span class="keyword">test</span></span><br></pre></td></tr></table></figure>
<p>其中，<code>trainpref</code>、<code>validpref</code>和<code>testpref</code>代表两个语言对应文件的前缀（路径和文件名的前缀），<code>source-lang</code>和<code>target-lang</code>两个参数代表两个语言对应文件的后缀名（不代表具体语言，只是通过后缀区分两种语言的数据），fairseq通过这几个参数的组合，来寻找对应的文本数据。</p>
<p>例如我们的数据中只有训练数据和测试数据，且文件后缀为<code>src</code>和<code>tgt</code>，即<code>train.src</code>、<code>train.tgt</code>、<code>test.src</code>和<code>test.tgt</code>，那么通过指定<code>--source-lang src --target-lang tgt --trainpref train --testpref test</code>，也可以读取的对应的文件。</p>
<p>预处理命令首先会从训练文本数据中构建词表。在默认情况下，会将所有出现过的单词根据词频排序，并将这个排序后的单词列表作为最终的词表。同时，fairseq还提供了相关的参数来自定义词表：</p>
<p><code>--thresholdsrc/--thresholdtgt</code>，分别对应源端（source）和目标端（target）的词表的最低词频，词频低于这个阈值的单词将不会出现在词表中，而是统一使用一个unknown标签来代替。</p>
<p><code>--srcdict/--tgtdict</code>，其参数为一个文件名，即使用已有的词表，而不去根据文本数据中单词的词频构建词表。已有的词表文件中，每一行包含一个单词及其词频（这个词频只作为排序和阈值过滤的依据，不代表实际的词频）。</p>
<p><code>--nwordssrc/--nwordstgt</code>，源端和目标端词表的大小，在对单词根据词频排序后，取前n个词来构建词表，剩余的单词使用一个统一的unknown标签代替。</p>
<p><code>--joined-dictionary</code>，源端和目标端使用同一个词表，对于相似语言（如英语和西班牙语）来说，有很多的单词是相同的，使用同一个词表可以降低词表和参数的总规模。</p>
<p>构建的词表是一个单词和序号之间的一对一映射，这个序号是单词在词表中的下标位置。预处理命令在构建词表之后，会将文本数据转换为数值形式，也就是把文本中的每一个词，转换为对应的序号。之后，数值化的文本数据会被进一步编码，默认情况下使用Memory-Mapped IndexedDataset，这种数据编码方式不仅可以压缩文件大小，还可以根据索引进行随机读取，因此在训练的时候不需要加载全部数据，从而节约内存使用。</p>
<p>二进制化的数据文件会默认保存在data-bin目录下，包括生成的词表、训练数据、验证数据和测试数据。也可以通过–destdir参数，将生成的数据保存在其他目录。</p>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>在对数据进行预处理之后，就可以开始训练翻译模型了。模型训练使用的命令是fairseq-train，在参数中需要指定训练数据、模型、优化器等参数：</p>
<figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">fairseq</span><span class="literal">-</span><span class="comment">train</span> <span class="comment">data</span><span class="literal">-</span><span class="comment">bin</span> --<span class="comment">arch</span> <span class="comment">transformer_iwslt_de_en</span> <span class="comment">\</span></span><br><span class="line"><span class="comment"></span>        --<span class="comment">max</span><span class="literal">-</span><span class="comment">tokens</span> <span class="comment">4096</span> --<span class="comment">max</span><span class="literal">-</span><span class="comment">update</span> <span class="comment">30000</span> <span class="comment">\</span></span><br><span class="line"><span class="comment"></span>        --<span class="comment">optimizer</span> <span class="comment">adam</span> --<span class="comment">lr</span><span class="literal">-</span><span class="comment">scheduler</span> <span class="comment">inverse_sqrt</span> --<span class="comment">lr</span> <span class="comment">0</span><span class="string">.</span><span class="comment">0007</span> <span class="comment">\</span></span><br><span class="line"><span class="comment"></span>        --<span class="comment">criterion</span> <span class="comment">label_smoothed_cross_entropy</span> --<span class="comment">label</span><span class="literal">-</span><span class="comment">smoothing</span> <span class="comment">0</span><span class="string">.</span><span class="comment">1</span> <span class="comment">\</span></span><br><span class="line"><span class="comment"></span>        --<span class="comment">no</span><span class="literal">-</span><span class="comment">progress</span><span class="literal">-</span><span class="comment">bar</span> --<span class="comment">save</span><span class="literal">-</span><span class="comment">interval</span><span class="literal">-</span><span class="comment">updates</span> <span class="comment">1000</span> </span><br></pre></td></tr></table></figure>

<p>fairseq-train提供了大量的训练参数，从而进行定制化的训练过程，其中主要的参数可以分为数据（data）、模型（model）、优化（optimizing）、训练（分布式和多GPU等）、日志（log）和模型保存（checkpointing）等。</p>
<ol>
<li>数据部分</li>
</ol>
<p>数据部分的常用参数主要有训练数据的位置（路径），训练时的batch size等。其中，batch size可以通过两种方法指定，<code>--max-tokens</code>是按照词的数量来分的batch，比如<code>--max-tokens 4096</code>指每个batch中包含4096个词；另外还可以通过句子来指定，如<code>--max-sentences 128</code>指每个batch中包含128个句子。</p>
<ol start="2">
<li>模型部分</li>
</ol>
<p>模型部分的参数主要有<code>--arch</code>，用指定所使用的网络模型结构，有大量预设的可以选择。其命名一般为“model_setting”，如“transformer_iwslt_de_en”就是使用Transformer模型和预设的iwslt_de_en超参数。在大数据上进行训练的时候，可以选择“transformer_wmt_en_de”、“transformer_wmt_en_de_big”等设置。除了Transformer之外，还有LSTM、FConv等模型及对应的预设超参数可以选择。</p>
<p>在使用预设模型的同时，还可以通过额外的命令行参数来覆盖已有的参数，如“transformer_wmt_en_de”中预设的编码器层数是6，可以通过<code>--encoder-layers 12</code>将编码器改为12层。</p>
<ol start="3">
<li>优化部分</li>
</ol>
<p>通过<code>--criterion</code>可以指定使用的损失函数，如cross_entropy等。和<code>--arch</code>参数一样，也可以通过命令行参数来覆盖特定损失的默认参数，比如通过<code>--label-smoothing</code>0.1，可以将label_smoothed_cross_entropy损失中默认为0的label-smoothing值改为0.1。</p>
<p>通过<code>--optimizer</code>可以指定所使用的优化器，如adam、sgd等；通过<code>--lr-scheduler</code>可以指定学习率缩减的方式。</p>
<p>通常来说，参数优化紧跟梯度计算，即每计算一次梯度，就会进行一次参数更新。在某些时候，我们希望在多次梯度计算之后进行一次更新，来模拟多GPU训练，可以通过–update-freq来指定，比如在单个GPU上指定“–update-freq 4”来训练，结果和4个GPU训练是基本等价的。</p>
<ol start="4">
<li>训练部分</li>
</ol>
<p>Fairseq支持单GPU、多GPU、多机器等多种训练方式，在默认情况下，会根据当前机器的GPU数量来确定训练方式。在绝大多数情况下，这部分参数都不需要关心，而是通过系统环境变量的方式，<code>export CUDA_VISIBLE_DEVICES=0,1</code>,来指定单卡、多卡训练。</p>
<p>如果所使用的GPU支持半精度，那么可以通过参数<code>--fp16</code>进行混合精度训练，可以极大提高模型训练的速度。通过<code>torch.cuda.get_device_capability(0)[0]</code>可以确定GPU是否支持半精度，如果该值小于7则不支持，大于等于7则支持。</p>
<ol start="5">
<li>日志和模型保存</li>
</ol>
<p>在默认情况下，fairseq使用tqdm和进度条来展示训练过程，但是这种方法不适合长时间在后台进行模型训练。通过<code>--no-progress-bar</code>参数可以改为逐行打印日志，方便保存。默认情况下，每训练100步之后会打印一次，通过<code>--log-interval</code>数可以进行修改。<br>Fairseq在训练过程中会保存中间模型，保存的位置可以通过–save-dir指定，其默认为checkpoints。中间模型保存的频率有两种指定方式，<code>--save-interval</code>指定了每N个epoch（遍历训练数据N次）保存一次；<code>--save-interval-updates</code>指定了每N步保存一次，这种通过step来保存模型的方法目前更为常用。<br>Note：在使用多GPU训练时，指定的batch size（max tokens或max sentences）是单个GPU上的数量，以token计算为例，最终batch size的大小为max-tokens、GPU数量、update-freq的乘积。</p>
<h2 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h2><p>在经过了充分训练之后，就可以使用模型来进行翻译了。Fairseq提供了两种解码的方式：批生成解码（fairseq-generate）和交互式解码（fairseq-interactive）。</p>
<ol>
<li>fairseq-generate</li>
</ol>
<p>fairseq-generate用来解码之前经过预处理（fairseq-preprocess）的数据：</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fairseq-<span class="keyword">generate</span> data-bin --path checkpoints/checkpoint_best<span class="variable">.pt</span> --remove-bpe</span><br></pre></td></tr></table></figure>

<p>默认情况下，这个命令会从预处理的数据中，解码测试数据（test set）。通过—gen-subset可以指定解码其他部分，如<code>--gen-subset train</code>就会翻译整个训练数据。<br>如果不想得到翻译结果，只想看到翻译结果的BLEU分值，可以通过—quiet参数，只显示翻译进度和最后打分。</p>
<p>通过<code>--beam</code>、<code>--lenpen</code>和<code>--unkpen</code>，可以分别设置beam search中的beam size，长度惩罚和unk惩罚。</p>
<p>参数<code>--remove-bpe</code>可以指定对翻译结果的后处理，由于在准备数据的时候，使用了BPE切分，该参数会把BPE切分的词合并为完整的单词。如果不加该参数，则输出的翻译结果和BLEU打分都是按照未合并BPE进行的。如果准备数据时BPE切分使用的是sentencepiece（<a target="_blank" rel="noopener" href="https://github.com/google/sentencepiece%EF%BC%89%EF%BC%8C%E9%82%A3%E4%B9%88%E5%8F%82%E6%95%B0%E7%9A%84%E5%80%BC%E8%BF%98%E5%8F%AF%E4%BB%A5%E8%AE%BE%E4%B8%BA%60--remove-bpe">https://github.com/google/sentencepiece），那么参数的值还可以设为`--remove-bpe</a> sentencepiece`，以合并sentencepiece的切分。</p>
<ol start="2">
<li>fairseq-interactive</li>
</ol>
<p>fairseq-interactive可以进行交互式逐句解码，其参数和fairseq-generate基本一致。以下命令用来逐行翻译test.de文件中的句子：</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">cat</span> test.de | fairseq-interactive <span class="class"><span class="keyword">data</span>-bin <span class="comment">--path checkpoints/checkpoint_best.pt --remove-bpe</span></span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>保存翻译结果</li>
</ol>
<p>在默认情况下，两种解码方式会将翻译结果直接显示出来，如果想保存翻译结果，可以通过<code>--results-path</code>参数来指定保存结果的位置，或者可以通过重定向的方法将输出保存到文件：</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fairseq-<span class="keyword">generate</span> someargs &gt; result<span class="variable">.txt</span></span><br></pre></td></tr></table></figure>

<p>这两种方法得到的翻译结果文件，包含了解码日志（log）、原文、译文、打分等信息，并且顺序与原文不一致，通过以下命令可以得到排序后的译文：</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">grep</span> ^H result.txt | <span class="keyword">sort</span> -n -k <span class="number">2</span> -t <span class="string">&#x27;-&#x27;</span> | cut -f <span class="number">3</span></span><br></pre></td></tr></table></figure>


<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文以训练一个简单翻译模型为例，介绍了fairseq几个命令行工具（fairseq-preprocess、train、generate、interactive）的基本使用方法。通过命令行调用的方法，可以在不接触内部代码的情况下，完成训练解码的整个流程。</p>
<p>在后续的文章中，将会陆续介绍fairseq的扩展方法，比如定义新的任务，实现新的模型等。</p>

  </div>
  <!--文末结束语-->
  
  <div class="mdui-divider"></div>
  
  <nav>
    
    
      <a rel="next" class="post-nav-item mdui-float-right" href="/2020/10/12/fairseq-2/">
        <span>Fairseq漫游指南（2）——扩展模型</span>
        <i class="iconfont icon-angle-right"></i>
      </a>
    
  </nav>
</article>




  <div class="toc-button"  style="z-index: 100;">
    <button class="mdui-fab mdui-ripple mdui-color-teal" mdui-menu="{target: '#toc'}"><i class="iconfont icon-list"></i></button>
    <ul class="mdui-menu" id="toc">
      <li class="mdui-menu-item">
        <a href="/2020/10/12/fairseq-1/" id="toc-header" class="mdui-ripple">文章目录</a>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-number">1.</span> <span class="toc-text">环境搭建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-number">2.</span> <span class="toc-text">准备数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%96"><span class="toc-number">3.</span> <span class="toc-text">数据二进制化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">4.</span> <span class="toc-text">模型训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81"><span class="toc-number">5.</span> <span class="toc-text">解码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li></ol>
      </li>
    </ul>
  </div>


  </main>
  <footer id="footer" class="mdui-text-center mdui-m-t-5 mdui-p-b-2 mdui-p-t-4 mdui-color-theme">
  <div class="mdui-container">
    <div class="mdui-row">
      <span>
        &copy; 2015 - 2020 
        
          <span style="color: #d9333f" class="iconfont icon-heart"></span>
        
        Qian Wang
      </span>
    </div>
    <div class="mdui-row">
      
        <div class="mdui-col-xs-12">
          <span>Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a></span>
        </div>
      
    </div>
 </div>
</footer>
  
  <button id="gotop" class="mdui-fab mdui-fab-fixed mdui-fab-hide mdui-ripple mdui-color-teal" style="z-index:100;"><i class="iconfont icon-arrowup"></i></button>
  
  







    
<script src="/js/mdui.min.v1.0.0.js"></script>




<script src="/js/meadow.js"></script>

</body>
</html >